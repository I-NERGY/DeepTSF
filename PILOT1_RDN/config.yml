mlflow_settings:
    mlflow_tracking_uri: http://147.102.6.64:5000
  # mlflow_s3_endpoint_url: http://147.102.6.64:9000
  # minio_settings:
  #     aws_access_key_id: accessminio
  #     aws_secret_access_key: secretminio

hyperparameters:
  test:
    model: LSTM
    n_rnn_layers: 1
    hidden_dim:  1 #128
    n_epochs: 1
    input_chunk_length: 3
    training_length: 3
    random_state: 0
    nr_epochs_val_period: 1
    dropout: 0
    learning_rate: 0.005
    # likelihood: Gaussian
    batch_size: 8

  lstm2:
    model: LSTM
    n_rnn_layers: 1
    hidden_dim:  8 #128
    n_epochs: 150
    input_chunk_length: 192
    training_length: 192
    random_state: 42
    nr_epochs_val_period: 2
    dropout: 0
    learning_rate: 0.001
    # likelihood: Gaussian
    batch_size: 512

  lstm1:
    model: LSTM
    n_rnn_layers: 2
    hidden_dim:  20 #128
    n_epochs: 120
    input_chunk_length: 672
    training_length: 672
    random_state: 0
    nr_epochs_val_period: 1
    dropout: 0.1
    learning_rate: 0.0008
    # likelihood: Gaussian
    batch_size: 1024

  lstm3:
    model: LSTM
    n_rnn_layers: 3
    hidden_dim:  64 #128
    n_epochs: 200
    input_chunk_length: 192
    training_length: 192
    random_state: 0
    nr_epochs_val_period: 2
    dropout: 0
    learning_rate: 0.0005
    # likelihood: Gaussian
    batch_size: 512
  
  lstm4:
    model: LSTM
    n_rnn_layers: 3
    hidden_dim:  64 #128
    n_epochs: 200
    input_chunk_length: 672
    training_length: 672
    random_state: 0
    nr_epochs_val_period: 2
    dropout: 0
    learning_rate: 0.0005
    # likelihood: Gaussian
    batch_size: 512

  blockrnn:
    model: LSTM
    input_chunk_length: 192
    output_chunk_length: 96
    hidden_size:  16
    n_epochs: 200
    random_state: 0
    nr_epochs_val_period: 2
    dropout: 0
    learning_rate: 0.0008
    batch_size: 512
    
  nbeats:
    input_chunk_length: 192
    output_chunk_length: 96
    num_stacks: 20
    num_blocks: 1
    num_layers: 4
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 80
    random_state: 42
    nr_epochs_val_period: 2
    # likelihood: Gaussian
    batch_size: 512

  nbeats2:
    input_chunk_length: 286
    output_chunk_length: 96
    num_stacks: 20
    num_blocks: 1
    num_layers: 4
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 60
    random_state: 42
    nr_epochs_val_period: 2
    batch_size: 128

  nbeats3:
    input_chunk_length: 378
    output_chunk_length: 96
    num_stacks: 20
    num_blocks: 1
    num_layers: 4
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 60
    random_state: 42
    nr_epochs_val_period: 2
    batch_size: 128

# preprocessing:
#   data_root: ../../RDN/Load Data (2018-2019)/artifacts
#   timestep: 15 # minutes

# training:
#   cut_date_val: 20190901
#   cut_date_test: 20191201
#   dot_darts_path: ./.darts
#   darts_model: RNNModel
#   hyperparameters:
#     model: LSTM
#     n_rnn_layers: 1
#     hidden_dim: 128
#     n_epochs: 200
#     input_chunk_length: 120
#     training_length: 120 # should be >= input_chunk
#     random_state: 42
#     nr_epochs_val_period: 1
#     dropout: 0
#     learning_rate: 0.0005
#     batch_size: 32
#     # likelihood: darts.utils.likelihood_models.GaussianLikelihood

evaluation:
  dot_darts_path: .darts
  model_name: LSTM_120 #leave it blank if training step is run as well
  transformer_filename: scaler.pkl # it is supposed to be in the same folder with the model
  backtest_start_date: 20191201