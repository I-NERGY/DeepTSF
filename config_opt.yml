hyperparameters:

  transformer_test:
    input_chunk_length: ["list", 6, 12, 24, 48, 76]
    output_chunk_length: 1
    d_model: ["list", 32, 64]
    nhead: ["list", 2, 3]
    num_encoder_layers: 3
    num_decoder_layers: ["range", 1, 3, 1]
    dim_feedforward: 512
    dropout: 0.1 
    activation: 'relu'
    n_epochs: 2
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: 32

  nhits_test_new:
    input_chunk_length: ["list", 6, 12, 24, 48, 76]
    output_chunk_length: 1
    num_stacks: ["range", 1, 5, 1]
    num_blocks: ["range", 1, 5, 1]
    num_layers: ["range", 1, 3, 1]
    layer_widths: 64
    n_epochs: 2
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: 32

  lstm_test:
     model: LSTM
     n_rnn_layers: ["list", 1, 2, 3]
     hidden_dim:  ["list", 32, 64]
     n_epochs: 50
     input_chunk_length: 6
     training_length: 6
     random_state: 0
     nr_epochs_val_period: 2
     dropout: 0.3
     learning_rate: ["list", 0.01, 0.001]
     # likelihood: Gaussian
     batch_size: ["list", 16, 32]


  TCN_val_2020:
    output_chunk_length: 24
    weight_norm: True
    dropout: 0
    nr_epochs_val_period: 2
    n_epochs: 500
    random_state: 0
    input_chunk_length: ["range", 48, 480, 24]
    kernel_size: ["range", 2, 6, 1]
    num_filters: ["range", 2, 12, 1]
    dilation_base: ["list", 2, 4, 8, 16, 32]
    batch_size: ["list", 256, 512, 1024, 1280, 1536, 2048]

#An ta layers bgainoun symantikotero karfwse ta 4
#kai 19 kai 20
  NBEATS_thesis:
    input_chunk_length: ["range", 120, 312, 24]
    output_chunk_length: 24
    num_stacks: ["range", 1, 10, 1]
    num_blocks: ["range", 1, 6, 1]
    num_layers: ["range", 1, 10, 1]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 200
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: 1024

  NBEATS_thesis_multiple:
    input_chunk_length: ["range", 120, 312, 24]
    output_chunk_length: 24
    num_stacks: ["range", 1, 10, 1]
    num_blocks: ["range", 1, 6, 1]
    num_layers: ["range", 1, 10, 1]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 200
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: 1024
    scale:  ["list", "True", "False"]

  NBEATS_uc7_mase:
    input_chunk_length: ["range", 120, 312, 24]
    output_chunk_length: 24
    num_stacks: ["range", 1, 10, 1]
    num_blocks: ["range", 1, 6, 1]
    num_layers: ["range", 1, 10, 1]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 200
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: 1024

  LightGBM_thesis_multiple:
    lags: ["range", 120, 312, 24]
    lags_past_covariates: null
    lags_future_covariates: None
    future_covs_as_tuple: true
    random_state: 0
    scale: ["list", "True", "False"]

  NBEATS_testt:
    input_chunk_length: ["range", 120, 312, 24]
    output_chunk_length: 24
    num_stacks: ["range", 1, 10, 1]
    num_blocks: ["range", 1, 6, 1]
    num_layers: ["range", 1, 10, 1]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 2
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: 1024

  BlockLSTM_val_2020_:
    model: LSTM
    n_rnn_layers: ["range", 1, 4, 1] #kospe an yparxei thema
    input_chunk_length: ["range", 24, 480, 24]
    output_chunk_length: 24
    hidden_dim:  ["range", 24, 240, 24] #hmerisio???
    n_epochs: 2
    random_state: 0
    nr_epochs_val_period: 2
    dropout: 0
    learning_rate: 0.001
    batch_size: ["list", 256, 512, 1024, 1280, 1536, 2048]
    scale:  ["list", "True", "False"]

  MLP_val_2020:
    hidden_layer_sizes : # n_layers=[1,10, 1], n_neur=[50, 200, 10]
    activation: ["list", "relu", "logistic"]
    solver: 'adam'
    alpha: 0.0001
    batch_size: 'auto' #print and save the batch size
    learning_rate: 'constant'
    learning_rate_init: ["range", 0.0005, 0.002, 0.0005] #asto karfwmeno
    max_iter: 200
    shuffle: ["list", "True", "False"]
    random_state: 0
    verbose: True
    early_stopping: True
    validation_fraction: 0.13
    tolerance: 1e-06
    n_iter_no_change: 10
                          #kai lbw bale
                          #trekse apo script
  NBEATS_val_2020_5_13:
    input_chunk_length: ["range", 120, 312, 24]
    output_chunk_length: 24
    num_stacks: ["range", 1, 25, 1]
    num_blocks: ["range", 1, 20, 1]
    num_layers: ["range", 1, 10, 1]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 300
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: ["list", 256, 512, 1024, 1280, 1536, 2048]

  NBEATS_val_2020_17_23_test:
    input_chunk_length: ["range", 408, 552, 24]
    output_chunk_length: 24
    num_stacks: ["range", 1, 25, 1]
    num_blocks: ["range", 1, 20, 1]
    num_layers: ["range", 1, 10, 1]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 2
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: ["list", 256, 512, 1024, 1280, 1536, 2048]

  NBEATS_15min:
    input_chunk_length: ["range", 96, 672, 96]
    output_chunk_length: 96
    num_stacks: ["range", 1, 20, 2]
    num_blocks: ["range", 1, 5, 1]
    num_layers: ["range", 1, 5, 1]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 500
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: 1024

  NHiTS_15min:
    input_chunk_length: ["range", 96, 672, 96]
    output_chunk_length: 96
    num_stacks: ["range", 1, 20, 2]
    num_blocks: ["range", 1, 5, 1]
    num_layers: ["range", 1, 5, 1]
    layer_widths: 64
    n_epochs: 500
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: 1024

  TCN_15min:
    output_chunk_length: 96
    weight_norm: True
    dropout: 0
    nr_epochs_val_period: 2
    n_epochs: 500
    random_state: 0
    input_chunk_length: ["range", 192, 672, 96]
    kernel_size: ["range", 2, 5, 1]
    num_filters: ["range", 2, 6, 1]
    dilation_base: ["list", 2, 3, 4]
    batch_size: 1024

  BlockLSTM_15min:
    model: LSTM
    n_rnn_layers: ["range", 2, 4, 1]
    input_chunk_length: ["range", 96, 672, 96]
    output_chunk_length: 96
    hidden_dim:  ["list", 16, 32, 64, 128] 
    n_epochs: 500
    random_state: 0
    nr_epochs_val_period: 2
    dropout: 0
    learning_rate: 0.001
    batch_size: 1024
    
  MLP_15min:
    #hidden_layer_sizes : # n_layers=[1, 4, 1], n_neur=[16, 32, 64, 128, 256]
    #activation: relu
    #solver: 'adam'
    #alpha: 0.0001
    #batch_size: 'auto' #print and save the batch size
    #learning_rate: 'constant'
    #learning_rate_init: ["range", 0.0005, 0.002, 0.0005] #asto karfwmeno
    #max_iter: 200
    #shuffle: ["list", "True", "False"]
    #random_state: 0
    #verbose: True
    #early_stopping: True
    #validation_fraction: 0.13
    #tolerance: 1e-06
    n_iter_no_change: 10

  nbeats_test_3:
    input_chunk_length: ["range", 3, 12, 3]
    output_chunk_length: 1
    num_stacks: ["range", 1, 12, 1]
    num_blocks: ["range", 1, 12, 1]
    num_layers: ["range", 1, 12, 1]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 3
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: ["list", 8, 16, 32, 64]

  lgbm_3d:
    lags: ["list", 48, 24]
    lags_past_covariates: null
    lags_future_covariates: [1, 1]
    future_covs_as_tuple: true
    random_state: 0

  TFT_paper_final:
    input_chunk_length: ["range", 24, 480, 24]
    output_chunk_length: 24
    lstm_layers: ["list", 1, 2, 4]
    dropout: ["list", 0.1, 0.2, 0.3, 0.4, 0.5]
    num_attention_heads: ["list", 1, 4] 
    hidden_size: ["list", 16, 32, 64, 128, 256]
    batch_size: ["list", 256, 512, 1024, 1280, 1536, 2048]
    add_relative_index: "True"
    scale:  ["list", "True", "False"]

  TFT_paper_true_final:
    input_chunk_length: ["list", 72, 168, 192, 312, 336, 360]
    output_chunk_length: 24
    lstm_layers: ["list", 1, 2, 3, 4]
    dropout: ["list", 0, 0.1, 0.3, 0.5, 0.7, 0.9]
    num_attention_heads: ["list", 1, 4]
    hidden_size: ["list", 32, 64, 128, 256]
    batch_size: ["list", 256, 512, 1024, 1280, 1536]
    n_epochs: 150
    add_relative_index: "True"
    scale: "True"

  LSTM_prob_paper:  
    model: LSTM
    n_rnn_layers: ["range", 1, 4, 1]
    input_chunk_length: ["range", 24, 480, 24]
    output_chunk_length: 24
    hidden_dim:  ["range", 24, 240, 24]
    n_epochs: 300
    random_state: 0
    nr_epochs_val_period: 2
    dropout: 0
    learning_rate: 0.001
    batch_size: ["list", 256, 512, 1024, 1280, 1536, 2048]
    likelihood: "Gaussian"
    training_length: ["equal", "input_chunk_length"]
    scale:  ["list", "True", "False"]

  NBEATS_weather:
    input_chunk_length: ["list", 168, 192]
    output_chunk_length: 24
    num_stacks: ["list", 3, 4, 5]
    num_blocks: ["list", 1,2,4,6,8,10]
    num_layers: ["list", 2,3,4,5,6]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 200
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: ["list", 256, 512, 1024, 1536]

  NBEATS_shifted_weather:
    input_chunk_length: ["range", 48, 240, 24]
    output_chunk_length: 24
    num_stacks: ["range", 1, 10, 1]
    num_blocks: ["range", 1, 10, 1]
    num_layers: ["range", 1, 5, 1]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 300
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: ["list", 256, 512, 1024, 1280, 1536, 2048]

  NBEATS_unshifted_weather_:
    input_chunk_length: ["range", 48, 240, 24]
    output_chunk_length: 24
    num_stacks: ["range", 1, 10, 1]
    num_blocks: ["range", 1, 10, 1]
    num_layers: ["range", 1, 5, 1]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 300
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: ["list", 256, 512, 1024, 1280, 1536, 2048]
  
  NBEATS_example__:
    input_chunk_length: ["range", 48, 240, 24]
    output_chunk_length: 24
    num_stacks: ["range", 1, 10, 1]
    num_blocks: ["range", 1, 10, 1]
    num_layers: ["range", 1, 5, 1]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 2
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: ["list", 256, 512, 1024, 1280, 1536, 2048]

  NBEATS_river:
    input_chunk_length: ["range", 48, 480, 24]
    output_chunk_length: 12
    num_stacks: ["range", 1, 10, 1]
    num_blocks: ["range", 1, 10, 1]
    num_layers: ["range", 1, 5, 1]
    generic_architecture: True
    layer_widths: 64
    expansion_coefficient_dim: 5
    n_epochs: 300
    random_state: 0
    nr_epochs_val_period: 2
    batch_size: 128

  TCN_river:
    output_chunk_length: 12
    weight_norm: True
    dropout: 0
    nr_epochs_val_period: 2
    n_epochs: 300
    random_state: 0
    input_chunk_length: ["range", 48, 480, 24]
    kernel_size: ["range", 2, 6, 1]
    num_filters: ["range", 2, 12, 1]
    dilation_base: ["list", 2, 4, 8, 16, 32]
    batch_size: 128
  
  LGBM_river_right:
    lags: ["range", 48, 420, 24]
    lags_past_covariates: ["range", 48, 420, 24]
    random_state: 0

  LGBM_uc7____:
    lags: ["range", 24, 96, 24]
    lags_future_covariates: ["range", 24, 96, 24]
    random_state: 0

  LGBM_UC6_W4_AC_RAD:
    lags: ["range", 24, 96, 24]
    lags_future_covariates: ["range", 24, 96, 24]
    output_chunk_length: 24
    random_state: 0

  LGBM_UC6_W6_AC_NOW:
    lags: ["range", 24, 96, 24]
    output_chunk_length: 24
    random_state: 0

  LGBM_UC6_W4_AC_W19_:
    lags: ["range", 24, 96, 24]
    lags_future_covariates: ["range", 24, 96, 24]
    output_chunk_length: 24
    random_state: 0

  LGBM_UC6_W6_RAD_1_3:
    lags: ["list", 1, 3]
    lags_future_covariates: ["list", 1, 3, 6, 12, 24, 48, 72]
    output_chunk_length: 24
    random_state: 0

  LGBM_UC6_W4_AC_NW_1h:
    lags: ["range", 24, 96, 24]
    output_chunk_length: 1
    random_state: 0
